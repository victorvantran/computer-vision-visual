{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9bb8986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.2\n",
      "Python 3.7.15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__) # 2.9.2\n",
    "!python --version # 3.7.15\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c3995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\segmentation_master\n",
      "TensorFlow Model is  6298629 bytes\n",
      "TFLite Model is      1900824 bytes\n",
      "Post training quantization saves 4397805 bytes\n",
      "Time elapsed: 30.937965869903564\n"
     ]
    }
   ],
   "source": [
    "%cd G:\\segmentation_master\n",
    "\n",
    "TFLITE_NAME = \"mobilenetv3_257x257\"\n",
    "\n",
    "DATASETS_DIR = r\"datasets\"\n",
    "ADE_DATASET_DIR = os.path.join(DATASETS_DIR, \"ADE\")\n",
    "ADE_DATASET_MISC_DIR = os.path.join(ADE_DATASET_DIR, \"miscellaneous\")\n",
    "REPRESENTATIVE_DATASET_FILEPATH = os.path.join(ADE_DATASET_MISC_DIR, \"representative.npy\")\n",
    "CREATED_MODELS_DIR = r\"models/created_models\"\n",
    "TFLITE_DIR = os.path.join(CREATED_MODELS_DIR, TFLITE_NAME)\n",
    "FROZEN_GRAPH_FILEPATH = os.path.join(TFLITE_DIR,str(TFLITE_NAME)+str(\".pb\"))\n",
    "TFLITE_FILEPATH = os.path.join(TFLITE_DIR,str(TFLITE_NAME)+str(\".tflite\"))\n",
    "\n",
    "def representative_dataset():\n",
    "    dataset = np.load(REPRESENTATIVE_DATASET_FILEPATH)\n",
    "    for data in dataset:\n",
    "      data = data.astype(np.float32)\n",
    "      #data = data / 127.5 - 1\n",
    "      yield [data]\n",
    "\n",
    "def frozen_to_tflite(tflite_filepath, frozen_graph_filepath, representative_dataset_filepath):\n",
    "    # Load the TensorFlow model\n",
    "    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\n",
    "        graph_def_file = frozen_graph_filepath, \n",
    "        input_arrays = ['sub_2'], # For the Xception model it needs to be `sub_7`, for MobileNet it would be `sub_2`\n",
    "        output_arrays = ['ResizeBilinear_2'],\n",
    "        input_shapes={'sub_2':[1,257,257,3]}\n",
    "    )\n",
    "    # converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=MODEL_FILE)\n",
    "\n",
    "    # will add quantization and optimization if needed according to this documents\n",
    "    # https://www.tensorflow.org/lite/performance/post_training_quantization#dynamic_range_quantization\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.uint8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.uint8  # or tf.uint8\n",
    "\n",
    "    # Convert to TFLite Model\n",
    "    tflite_model = converter.convert()\n",
    "    tflite_path = tflite_filepath\n",
    "    tflite_model_size = open(tflite_path, 'wb').write(tflite_model)\n",
    "    tf_model_size = os.path.getsize(frozen_graph_filepath)\n",
    "    print('TensorFlow Model is  {} bytes'.format(tf_model_size))\n",
    "    print('TFLite Model is      {} bytes'.format(tflite_model_size))\n",
    "    print('Post training quantization saves {} bytes'.format(tf_model_size-tflite_model_size))\n",
    "    \n",
    "    \n",
    "def run_frozen_to_tflite():\n",
    "    if not os.path.isdir(TFLITE_DIR):\n",
    "        os.makedirs(TFLITE_DIR)\n",
    "    frozen_to_tflite(tflite_filepath=TFLITE_FILEPATH,\n",
    "                    frozen_graph_filepath=FROZEN_GRAPH_FILEPATH,\n",
    "                    representative_dataset_filepath=REPRESENTATIVE_DATASET_FILEPATH,\n",
    "                    )\n",
    "    \n",
    "start = time.time()\n",
    "run_frozen_to_tflite()\n",
    "end = time.time()\n",
    "print(\"Time elapsed: {}\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49da644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc483_tf2]",
   "language": "python",
   "name": "conda-env-cpsc483_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
